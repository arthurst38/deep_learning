{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Utilisation des CNNs avec Keras sur des données de paysage.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "VbswqLLSgMzK",
        "c6jAWFPyP85p",
        "eGazvkPxP0oX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurst38/deep_learning/blob/main/Utilisation_des_CNNs_avec_Keras_sur_des_donn%C3%A9es_de_paysage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be5uBRdgbhey"
      },
      "source": [
        "# Utilisation des CNNs avec Keras sur des données de paysage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-diCsctWfSh"
      },
      "source": [
        "## Vérification de l'utilisation de GPU\n",
        "\n",
        "Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S9vf7TtjjMa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW2_sMt8cSP-"
      },
      "source": [
        "## Téléchargement du dataset Landscape depuis un repo git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZXdRwk2Lq3i"
      },
      "source": [
        "!git clone https://github.com/nzmonzmp/dataset-landscape.git\n",
        "!ls dataset-landscape\n",
        "print(\"***\")\n",
        "!ls -l dataset-landscape/seg_train\n",
        "print(\"***\")\n",
        "!ls -l dataset-landscape/seg_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5hheTPDcdqN"
      },
      "source": [
        "## Import de TensorFlow et des autres librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvZJ4yH6cNHE"
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import typing\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import pandas\n",
        "import seaborn\n",
        "import sklearn.utils\n",
        "import sklearn.metrics\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zCSZcuhczAn"
      },
      "source": [
        "## Préparation des données\n",
        "\n",
        "Pour charger nos données, nous allons combiner plusieurs libraires : [OpenCV](https://opencv.org/), [NumPy](https://numpy.org/) et [scikit-learn](https://scikit-learn.org/stable/). Ces librairies seront appelées depuis la fonction `get_images`.\n",
        "\n",
        "Après avoir chargé chaque image, nous allons passer leur canaux en RGB puis les redimensionner à 150x150, enfin, par défaut, nous retournerons un dataset mélangé grâce à [`sklearn.utils.shuffle`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html).\n",
        "\n",
        "*Complétez la fonction `get_images` qui va chercher les images dans `dir_path` contenant un dossier par classe. Chaque dossier de classe contient l'ensemble des images de cette classe. Il vous faut attribuer le label correct à chaque image.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l84GytKmeZM7"
      },
      "source": [
        "label_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "\n",
        "\n",
        "def get_images(dir_path: pathlib.Path, shuffle: bool = True\n",
        "              ) -> typing.Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
        "  images = []\n",
        "  labels = []\n",
        "  file_paths  = []\n",
        "\n",
        "  # On itère sur les sous-dossier de la racine : ils correspondent chacun à une\n",
        "  # classe\n",
        "  for subdir_path in dir_path.iterdir():\n",
        "\n",
        "    # Attribuez le bon label en fonction du nom du dossier \"labels\"\n",
        "    # Votre code ici\n",
        "    label = None\n",
        "\n",
        "    # On ajoute chaque image du label (dossier) courant à notre dataset\n",
        "    for image_path in subdir_path.iterdir():\n",
        "      # Utilisation de OpenCV pour charger l'image\n",
        "      image = cv2.imread(str(image_path))\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      # En entrée d'un CNN, toutes les images doivent faire la même taille\n",
        "      image = cv2.resize(image, (150, 150))\n",
        "      images.append(image)\n",
        "      labels.append(label)\n",
        "      file_paths.append(image_path)\n",
        "\n",
        "  # Création des tableaux numpy que l'on va retourner\n",
        "  images, labels, file_paths = map(numpy.array, [images, labels, file_paths])\n",
        "\n",
        "  # Mélange de ces tableaux\n",
        "  if shuffle:\n",
        "    images, labels, file_paths = sklearn.utils.shuffle(images,\n",
        "                                                       labels,\n",
        "                                                       file_paths)\n",
        "  return images, labels, file_paths\n",
        "\n",
        "\n",
        "# get_images(pathlib.Path(\"dataset-landscape\") / \"seg_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbswqLLSgMzK"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kv62rzC3wIO"
      },
      "source": [
        "label_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "label_to_index = {l: i for i, l in enumerate(label_names)}\n",
        "\n",
        "\n",
        "def get_images(dir_path: pathlib.Path, shuffle: bool = True\n",
        "              ) -> typing.Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
        "  images = []\n",
        "  labels = []\n",
        "  file_paths  = []\n",
        "\n",
        "  # On itère sur les sous-dossier de la racine : ils correspondent chacun à une\n",
        "  # classe\n",
        "  for subdir_path in dir_path.iterdir():\n",
        "\n",
        "    # Attribuez le bon label en fonction du nom du dossier \"labels\"\n",
        "    # Votre code ici\n",
        "    label = label_to_index.get(subdir_path.name)\n",
        "\n",
        "    # On ajoute chaque image du label (dossier) courant à notre dataset\n",
        "    for image_path in subdir_path.iterdir():\n",
        "      # Utilisation de OpenCV pour charger l'image\n",
        "      image = cv2.imread(str(image_path))\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      # En entrée d'un CNN, toutes les images doivent faire la même taille\n",
        "      image = cv2.resize(image, (150, 150))\n",
        "      images.append(image)\n",
        "      labels.append(label)\n",
        "      file_paths.append(image_path)\n",
        "  images, labels, file_paths = map(numpy.array, [images, labels, file_paths])\n",
        "\n",
        "  # Mélange de ces tableaux\n",
        "  if shuffle:\n",
        "    images, labels, file_paths = sklearn.utils.shuffle(images,\n",
        "                                                       labels,\n",
        "                                                       file_paths)\n",
        "  return images, labels, file_paths\n",
        "\n",
        "\n",
        "# get_images(pathlib.Path(\"dataset-landscape\") / \"seg_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Co3AuagRdQ"
      },
      "source": [
        "## Appel à `get_images`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlWHQMqbgUi_"
      },
      "source": [
        "images, labels, file_paths = get_images(\n",
        "    pathlib.Path(\"dataset-landscape\") / \"seg_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9CFPgYahZ-_"
      },
      "source": [
        "print(f\"Forme des images : {images.shape}\")\n",
        "print(f\"Forme des labels : {labels.shape}\")\n",
        "print(f\"Forme des chemins : {file_paths.shape}\")\n",
        "\n",
        "seaborn.countplot(x=labels)\n",
        "plt.title(\"Décomptes des différents labels\")\n",
        "plt.ylabel(\"Décompte\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTCfZurx5Big"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRP8sepdhh8I"
      },
      "source": [
        "# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n",
        "# la taille de la figure qui est petite par défaut\n",
        "f, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
        "\n",
        "# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n",
        "# même image deux fois)\n",
        "random_indexes = numpy.random.choice(images.shape[0],\n",
        "                                     size=(5, 5),\n",
        "                                     replace=False)\n",
        "\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "    img_index = random_indexes[i, j]\n",
        "    image = images[img_index]\n",
        "    label = label_names[labels[img_index]]\n",
        "\n",
        "    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision par\n",
        "    # ordinateur\n",
        "    ax[i, j].imshow(image)\n",
        "    ax[i, j].set_title(f\"Exemple {img_index} ({label})\")\n",
        "    ax[i, j].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JOKqXxDP5jB"
      },
      "source": [
        "## Création du modèle\n",
        "\n",
        "Voici un exemple de CNN « minimaliste »"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFvhX0LZjZw3"
      },
      "source": [
        "# Initialisation et définition du modéle\n",
        "\n",
        "# Le modèle est un empilement de couches où le flux de données est séquentiel\n",
        "model = keras.models.Sequential()\n",
        "# Une première couche de 10 convolutions de 3x3 pixels\n",
        "model.add(keras.layers.Conv2D(1,\n",
        "                              kernel_size=(3, 3),\n",
        "                              activation=\"relu\",\n",
        "                              input_shape=(150, 150, 3)))\n",
        "# Une couche de max pooling\n",
        "model.add(keras.layers.MaxPool2D(3,3))\n",
        "\n",
        "# Une couche de manipulation des tenseurs : suppression de toutes les dimensions\n",
        "# sauf celle de batch et une autre qui contient toutes les valeurs\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# Une couche de sortie dense avec 6 neurones et un softmax comme activation\n",
        "model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
        "\n",
        "# Compilation du modèle avec la définition de la fonction de perte\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Affichage d'un résumé du modèle\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYBPo9koUi7k"
      },
      "source": [
        "## Pouvez-vous expliquer les différents nombres de paramètres ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6jAWFPyP85p"
      },
      "source": [
        "### Solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaRo4VICP_mh"
      },
      "source": [
        "Premier layer de 10 convolutions : (taille du kernel) * (nb kernel) * (nb canaux en entrée) + (nb biais (= nb kernel)) = (3 * 3 ) * 1 * 3 + 1\n",
        "\n",
        "Dernier layer dense : (input dim) * (output dim) + (nb biais) = 2401 * 6 + 6\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woNSPikeU_xl"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "Apprenons ce modèle sur nos données ! Dans un premier temps, nous entraînons sur une seule epoch pour simplement vérifier que notre modèle est opérationnel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vg7kkCCiyB_"
      },
      "source": [
        "# Apprentissage du modèle\n",
        "training_history = model.fit(images, labels, epochs=1, validation_split=0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSjwH-gwSx33"
      },
      "source": [
        "## Discussion sur les résultats\n",
        "\n",
        "- Quelle est la performance du modèle ?\n",
        "\n",
        "- À quoi correspond cette valeur ?\n",
        "\n",
        "- Qu'en déduire ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ffuXmAvTuqF"
      },
      "source": [
        "## Améliorez cette performance\n",
        "\n",
        "Inspirez-vous du modèle précédent en rajoutant des couches, en faisant des couches plus petites ou plus grosses.\n",
        "\n",
        "Visez entre 10 et 20 itérations et mois de 1 minute par itération (pour des raisons évidentes).\n",
        "\n",
        "On peut considérer l'utilisation d'une couche de dropout juste avant la dernière couche dense pour améliorer la régularisation.\n",
        "\n",
        "On peut obtenir une précision supérieure à 70% sur la base de validation en un temps raisonnable.\n",
        "\n",
        "La solution proposée prend $\\approx$ 45 secondes par itération pendant 15 itérations et atteint aux alentour de 85% d'accuracy sur la base de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-j7dwcWUdZx"
      },
      "source": [
        "# Vos améliorations ici\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(10,\n",
        "                              kernel_size=(3, 3),\n",
        "                              activation=\"relu\",\n",
        "                              input_shape=(150, 150, 3)))\n",
        "model.add(keras.layers.MaxPool2D(3,3))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Affichage d'un résumé du modèle\n",
        "model.summary()\n",
        "\n",
        "# Apprentissage du modèle\n",
        "training = model.fit(images, labels, epochs=10, validation_split=0.30)\n",
        "\n",
        "\n",
        "# Plot des métriques d'entraînement\n",
        "def plot_metrics(history) -> None:\n",
        "  plt.plot(training.history[\"accuracy\"])\n",
        "  plt.plot(training.history[\"val_accuracy\"])\n",
        "  plt.title(\"Accuracy du modèle\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper left\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(training.history[\"loss\"])\n",
        "  plt.plot(training.history[\"val_loss\"])\n",
        "  plt.title(\"Perte du modèle\")\n",
        "  plt.ylabel(\"Perte\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper right\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_metrics(training.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGazvkPxP0oX"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bIuRTZYAnWR"
      },
      "source": [
        "conv2d_params = dict(kernel_size=(3,3),\n",
        "                     activation=\"relu\",\n",
        "                     kernel_initializer=\"orthogonal\",\n",
        "                     padding=\"same\")\n",
        "\n",
        "dense_params = dict(activation=\"relu\", kernel_initializer=\"orthogonal\")\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(200, input_shape=(150, 150, 3), **conv2d_params))\n",
        "model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "model.add(keras.layers.MaxPool2D(2, 2, padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(rate=0.7))\n",
        "model.add(keras.layers.Dense(200, **dense_params))\n",
        "model.add(keras.layers.Dense(100, **dense_params))\n",
        "model.add(keras.layers.Dense(50, **dense_params))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(6,\n",
        "                             activation=\"softmax\",\n",
        "                             kernel_initializer=\"orthogonal\"))\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Affichage d'un résumé du modèle\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PsIIXF0hzy5"
      },
      "source": [
        "# Apprentissage du modèle\n",
        "training = model.fit(images,\n",
        "                     labels,\n",
        "                     epochs=15,\n",
        "                     validation_split=0.30,\n",
        "                     batch_size=128)\n",
        "\n",
        "# Visualisation des métriques d'entrainement\n",
        "plot_metrics(training.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb_IT9QWeYPh"
      },
      "source": [
        "## Évaluation des performances sur l'ensemble de test\n",
        "\n",
        "Dans le dossier `seg_test` se trouve un ensemble de données qui n'ont jamais été vues durant l'apprentissage.\n",
        "\n",
        "On utilisera la méthode `evaluate(X, y)` du modèle pour évaluer la qualité de nos prédictions sur ce dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJubx-J7i882"
      },
      "source": [
        "test_images,test_labels, test_file_paths = get_images(\n",
        "    pathlib.Path(\"dataset-landscape\") / \"seg_test\")\n",
        "model.evaluate(test_images, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYPaPc0lpe0B"
      },
      "source": [
        "## Analyse d'erreur\n",
        "\n",
        "On affiche la matrice de confusion puis on regarde des images mal classées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfOlRq1Ep3KD"
      },
      "source": [
        "test_pred = numpy.argmax(model.predict(test_images), axis=-1)\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(test_pred,\n",
        "                                                    test_labels,\n",
        "                                                    normalize=\"true\")\n",
        "seaborn.heatmap(confusion_matrix,\n",
        "                cmap=\"rocket_r\",\n",
        "                xticklabels=label_names,\n",
        "                yticklabels=label_names)\n",
        "plt.title(\"Matrice de confusion\")\n",
        "plt.show()\n",
        "\n",
        "seaborn.countplot(x=test_labels)\n",
        "plt.title(\"Décomptes des classes prédites\")\n",
        "plt.ylabel(\"Décompte\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLUCp97BeUxu"
      },
      "source": [
        "def plot_mistakes(predicted_class: str, true_class: str) -> None:\n",
        "  mistakes = test_images[(test_pred == label_to_index[predicted_class])\n",
        "                         & (test_labels == label_to_index[true_class])]\n",
        "  random_indexes = numpy.random.choice(mistakes.shape[0],\n",
        "                                       size=min(mistakes.shape[0], 25),\n",
        "                                       replace=False)\n",
        "  grid_indexes = itertools.product(range(5), repeat=2)\n",
        "\n",
        "  f, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
        "  for img_index, (i, j) in zip(random_indexes, grid_indexes):\n",
        "    ax[i, j].imshow(mistakes[img_index])\n",
        "    ax[i, j].axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43kc6Wgd9bkC"
      },
      "source": [
        "# Plot les images prédites glacier alors qu'elles ont un label montagne\n",
        "plot_mistakes(\"glacier\", \"mountain\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QyUe_6T_vL8"
      },
      "source": [
        "# Plot les images prédites glacier alors qu'elles ont un label mer\n",
        "plot_mistakes(\"glacier\", \"sea\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAgJItMSDE2-"
      },
      "source": [
        "# Plot les images prédites bâtiment alors qu'elles ont un label mer\n",
        "plot_mistakes(\"buildings\", \"sea\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Q5NiBKjO6X"
      },
      "source": [
        "## Prédire dans des condition « réelles »\n",
        "\n",
        "Dans le dossier `seg_pred` se trouvent des images non-annotées. On ne peut donc pas évaluer correctement les performances sur cet ensemble. \n",
        "\n",
        "Cependant, on peut afficher des photos et les probabilités que notre modèle attribue à chaque classe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yPf4WcytFzQ"
      },
      "source": [
        "pred_images, _, pred_file_paths = get_images(\n",
        "    pathlib.Path(\"dataset-landscape\") / \"seg_pred\")\n",
        "pred_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMLmuIqvWAS6"
      },
      "source": [
        "# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n",
        "# la taille de la figure qui est petite par défaut\n",
        "f, ax = plt.subplots(10, 5, figsize=(30, 45))\n",
        "\n",
        "# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n",
        "# même image deux fois)\n",
        "random_indexes = numpy.random.choice(pred_images.shape[0],\n",
        "                                     size=25,\n",
        "                                     replace=False)\n",
        "\n",
        "# On génère les indices 0, 2, 4, 6, 8 pour les lignes et de 0 à 4 pour les\n",
        "# colonnes de la grille de subplots (on travaillera les lignes 2 par 2).\n",
        "grid_indexes = itertools.product(range(0, 10, 2), range(5))\n",
        "\n",
        "for img_index, (i, j) in zip(random_indexes, grid_indexes):\n",
        "  # Récupération de l'image et prédiction de sa classe\n",
        "  image = pred_images[img_index]\n",
        "  probabilities = model.predict(image[None, ...])[0]\n",
        "  predicted_class = label_names[numpy.argmax(probabilities)]\n",
        "\n",
        "  # Affichage avec matplotlib et sa fonction imshow, très pratique en vision par\n",
        "  # ordinateur\n",
        "  ax[i, j].imshow(image)\n",
        "  ax[i, j].set_title(f\"Exemple {img_index}\")\n",
        "  ax[i, j].axis('off')\n",
        "\n",
        "  # Affichage de la distribution de prédiction sur la ligne d'en dessous (i + 1)\n",
        "  ax[i + 1, j].bar(label_names, probabilities)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}