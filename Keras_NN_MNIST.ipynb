{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras - NN - MNIST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "b43LPGjlO2md",
        "qFRfcLfDRSNr",
        "gB88nt7ld_BO",
        "gAnHfEQ4bjN2",
        "djYsEBTec1ba",
        "Lj6zes_CtoQU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurst38/deep_learning/blob/main/Keras_NN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQpyoS497Vuv"
      },
      "source": [
        "# Réseau de neurones simple avec Keras\n",
        "\n",
        "Dans ces travaux pratiques, nous allons voir comment utiliser Keras pour construire des réseaux de neurones simples.\n",
        "\n",
        "Il n'est pas nécessaire d'utiliser une carte graphique fournie par Colab pour ce TP, tout est rapide sur CPU. Vous pouvez donc changer d'environnement si celui qui vous a été attribué a une carte graphique (`Exécution > Modifier le type d'exécution`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp4PVOiUM0al"
      },
      "source": [
        "!pip install keras-tuner\n",
        "import datetime\n",
        "import typing\n",
        "\n",
        "import kerastuner\n",
        "import numpy\n",
        "import tensorflow\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRhv2bFpL4ed"
      },
      "source": [
        "## Récupération des données\n",
        "\n",
        "Cette fois nous allons récupérer le dataset par Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CYpYMI3NNq1"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyahQcGyN835"
      },
      "source": [
        "## Regardons les données\n",
        "\n",
        "Dans les cellules suivantes, étudiez comment sont stockées les données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg8RYhKbO0MJ"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b43LPGjlO2md"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEMqyNz9NRqU"
      },
      "source": [
        "print(f\"Format de X_train : {X_train.shape}\")\n",
        "print(f\"Format de X_test : {X_test.shape}\")\n",
        "print(f\"Format de y_train : {y_train.shape}\")\n",
        "print(f\"Format de y_test : {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdHCif72TF65"
      },
      "source": [
        "print(f\"X_train exemple : {X_train[0]}\")\n",
        "print(f\"X_train type : {X_train.dtype}\")\n",
        "print(f\"y_train exemple : {y_train[0]}\")\n",
        "print(f\"y_train type : {y_train[0].dtype}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqJS6nqSO73s"
      },
      "source": [
        "## Transformation des données\n",
        "\n",
        "Nous devons effectuer quelques transformations sur ces données :\n",
        "\n",
        "1. On pourrait conserver les formes originales des tableaux numpy `(_, 28, 28)` mais il sera plus aisé de travailler sur des tenseurs de forme `(_, 28²)` où `_` est le nombre original d'exemples.\n",
        "2. Le type actuel des tableaux est `uint8` comme nous venons de le voir. Keras utilise par défaut des `float32`. Il faut donc convertir nos tableaux.\n",
        "3. Nous allons voir deux manières de définir la fonction de perte. La première nécessite que les classes soit [one-hot encodées](https://fr.wikipedia.org/wiki/Encodage_one-hot).\n",
        "\n",
        "Quelques fonctions qui peuvent s'avérer utiles :\n",
        "\n",
        "- [`numpy.ndarray.reshape`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)\n",
        "- [`numpy.ndarray.astype`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html)\n",
        "- [`tensorflow.keras.utils.to_categorical`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)\n",
        "\n",
        "*Effectuez les deux premières transformations sur `X_train` et `X_test` et la dernière sur `y_train` et `y_test`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-CYjgTkO5Dx"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFRfcLfDRSNr"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llO68r8YRI7v"
      },
      "source": [
        "nb_classes = 10\n",
        "input_dim = 28 * 28\n",
        "\n",
        "# On veut mettre X « à plat » pour que l'input de notre réseau soit un vecteur\n",
        "# de taille input_dim\n",
        "X_train = X_train.reshape(-1, input_dim)\n",
        "X_test = X_test.reshape(-1, input_dim)\n",
        "\n",
        "# X est un numpy.ndarray de uint8. Les couches Keras attendent par défaut des\n",
        "# entrées float32\n",
        "X_train = X_train.astype(numpy.float32)\n",
        "X_test = X_test.astype(numpy.float32)\n",
        "\n",
        "# Conversion des classes en vecteurs sparse\n",
        "Y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = keras.utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLRZcVYzdUzt"
      },
      "source": [
        "## Normalisation des données\n",
        "\n",
        "Normalisons nos données à l'aide de [`numpy.mean`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) et [`numpy.std`](https://numpy.org/doc/stable/reference/generated/numpy.std.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfsE7qiBd_A0"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB88nt7ld_BO"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g1uRRcI0g-D"
      },
      "source": [
        "# Normalisation\n",
        "X_mean = X_train.mean(axis=0)\n",
        "X_std = X_train.std(axis=0)\n",
        "\n",
        "# Il y a des colonnes constantes (des pixels toujours à 0). Pour éviter les\n",
        "# divisions par zéro, on peut diviser par 1 dans ce cas\n",
        "X_std[X_std == 0] = 1\n",
        "\n",
        "\n",
        "def normalize(array: numpy.ndarray) -> numpy.ndarray:\n",
        "  return (array - X_mean) / X_std\n",
        "\n",
        "\n",
        "X_train = normalize(X_train)\n",
        "X_test = normalize(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ggF0DZpRKLW"
      },
      "source": [
        "## Création d'un modèle\n",
        "\n",
        "Créez un modèle sans couche cachée qui prend en input une image et qui essaye de prédire la classe correspondante.\n",
        "\n",
        "Affichez un résumé de ce modèle et expliquez les nombres que vous voyez.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSQ21YeKbeoR"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAnHfEQ4bjN2"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UF5ijuKT8ca"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(nb_classes,\n",
        "                             input_dim=input_dim,\n",
        "                             activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4ReIqLhcRH_"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "Effectuez un apprentissage de ce modèle sur les données.\n",
        "\n",
        "On utilisera :\n",
        "\n",
        "- 128 comme taille de batch\n",
        "- 10 itérations\n",
        "- 20% de la base de train comme base de validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3q7mfC0cw5v"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djYsEBTec1ba"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ehiTjEaUSna"
      },
      "source": [
        "# compile sert à « attacher » un optimiseur, une fonction de perte et des\n",
        "# métriques à un modèle\n",
        "model.compile(optimizer=\"sgd\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# fit utilise le modèle « compilé » dans une boucle d'entraînement complète\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_split=0.2)\n",
        "\n",
        "\n",
        "def evaluate(model: keras.models.Model, one_hot: bool) -> None:\n",
        "  score = model.evaluate(X_test, Y_test if one_hot else y_test, verbose=0)\n",
        "  print(f\"Perte sur le test : {score[0]}\")\n",
        "  print(f\"Accuracy sur le test : {score[1]}\")\n",
        "\n",
        "\n",
        "evaluate(model, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2DijNlMc4dC"
      },
      "source": [
        "Solution alternative qui utilise une loss permettant d'utiliser directement `y_train` plutôt que `Y_train` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go7VxDSUZBOC"
      },
      "source": [
        "model2 = keras.models.Sequential()\n",
        "model2.add(keras.layers.Dense(nb_classes,\n",
        "                              input_dim=input_dim,\n",
        "                              activation=\"softmax\"))\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(optimizer=\"sgd\",\n",
        "               loss=\"sparse_categorical_crossentropy\",\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "model2.fit(X_train,\n",
        "           y_train,\n",
        "           batch_size=128,\n",
        "           epochs=10,\n",
        "           verbose=1,\n",
        "           validation_split=0.2)\n",
        "\n",
        "evaluate(model2, one_hot=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OAItALqNvrd"
      },
      "source": [
        "Solution avec 4 couches cachés de taille 20, une régularisation L2 des paramètres ainsi qu'une initialisation orthogonale des matrices de poids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3r1BcvZLiUR"
      },
      "source": [
        "def build_deep_model() -> keras.models.Model:\n",
        "  hidden_params = dict(activation='relu',\n",
        "                      kernel_regularizer='l2',\n",
        "                      bias_regularizer=\"l2\",\n",
        "                      kernel_initializer='orthogonal')\n",
        "\n",
        "  model = keras.models.Sequential(name=\"deep_model\")\n",
        "  model.add(keras.layers.Dense(20, input_dim=input_dim, **hidden_params))\n",
        "  model.add(keras.layers.Dense(20, **hidden_params))\n",
        "  model.add(keras.layers.Dense(20, **hidden_params))\n",
        "  model.add(keras.layers.Dense(20, **hidden_params))\n",
        "  model.add(keras.layers.Dense(nb_classes,\n",
        "                               activation=\"softmax\",\n",
        "                               kernel_regularizer=\"l2\",\n",
        "                               bias_regularizer=\"l2\",\n",
        "                               kernel_initializer=\"orthogonal\"))\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "deep_model = build_deep_model()\n",
        "\n",
        "deep_model.compile(optimizer=\"adam\",\n",
        "                   loss=\"sparse_categorical_crossentropy\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "\n",
        "deep_model.fit(X_train,\n",
        "               y_train,\n",
        "               batch_size=128,\n",
        "               epochs=10,\n",
        "               verbose=1,\n",
        "               validation_split=0.2)\n",
        "evaluate(deep_model, one_hot=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8ygnb4BhRjr"
      },
      "source": [
        "## Recherche d'hyper-paramètres\n",
        "\n",
        "Pour trouver les hyper-paramètres optimaux, il est possible d'utiliser la librairie [`keras-tuner`](https://keras-team.github.io/keras-tuner/). Pour cela, il faut définir une fonction qui crée un modèle en échantillonant les paramètres. Référez-vous à l'exemple de la page d'accueil de Keras Tuner pour définir un modèle utilisable par Keras Tuner puis utilisez [le tuner basé sur les processus bayésiens](https://keras-team.github.io/keras-tuner/documentation/tuners/#bayesianoptimization-class) pour trouver les hyper-paramètres optimaux de votre modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U6hpOZytm3K"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj6zes_CtoQU"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvETi-hVhQoy"
      },
      "source": [
        "def build_model(hp: kerastuner.HyperParameters):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(input_dim=input_dim,\n",
        "                               units=hp.Int('units',\n",
        "                                            min_value=32,\n",
        "                                            max_value=512,\n",
        "                                            step=32),\n",
        "                               activation='relu'))\n",
        "  model.add(keras.layers.Dense(nb_classes, activation='softmax'))\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',\n",
        "                                      values=[1e-2, 1e-3, 1e-4])),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "tuner = kerastuner.tuners.bayesian.BayesianOptimization(\n",
        "  build_model,\n",
        "  objective=\"val_accuracy\",\n",
        "  max_trials=5,\n",
        "  executions_per_trial=3,\n",
        "  directory=f\"logs/hp-{now}\",\n",
        "  project_name=\"mnist\")\n",
        "\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQisyN_2jupo"
      },
      "source": [
        "tuner.search(X_train, y_train,\n",
        "             epochs=10,\n",
        "             batch_size=1500,\n",
        "             validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8J-QtINk7PD"
      },
      "source": [
        "tuner.results_summary()\n",
        "best_models = tuner.get_best_models()\n",
        "print(best_models[0].summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeu0ev2FceFa"
      },
      "source": [
        "## Utilisation de TensorBoard pour la visualisation de métriques\n",
        "\n",
        "Passer un callback [`tensorflow.keras.callbacks.TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) à `fit` dans son argument `callbacks` permet d'activer TensorBoard. On peut ensuite visualiser les entraînements directement dans Colab à l'aide de l'extension `tensorboard`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZvImWbbosQ"
      },
      "source": [
        "now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "deep_model = build_deep_model()\n",
        "\n",
        "deep_model.compile(optimizer=\"adam\",\n",
        "                   loss=\"sparse_categorical_crossentropy\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir=f\"logs/adam-{now}\")\n",
        "\n",
        "deep_model.fit(X_train, y_train, batch_size=3000, epochs=10,\n",
        "               callbacks=[tb_callback], validation_split=0.2)\n",
        "\n",
        "\n",
        "# Même modèle mais avec sgd comme optimiseur\n",
        "deep_model = build_deep_model()\n",
        "\n",
        "deep_model.compile(optimizer=\"sgd\",\n",
        "                   loss=\"sparse_categorical_crossentropy\",\n",
        "                   metrics=[\"accuracy\"])\n",
        "\n",
        "tb_callback = keras.callbacks.TensorBoard(log_dir=f\"logs/sgd-{now}\")\n",
        "\n",
        "deep_model.fit(X_train, y_train, batch_size=3000, epochs=10,\n",
        "               callbacks=[tb_callback], validation_split=0.2)\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}