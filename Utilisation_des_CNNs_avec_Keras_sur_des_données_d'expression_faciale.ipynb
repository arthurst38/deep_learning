{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Utilisation des CNNs avec Keras sur des données d'expression faciale.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "uj7vdViMlF3D",
        "CplV6KtynBbQ",
        "5Z0x2FNEory5",
        "gq8vcEL8o78Z",
        "N4jMT76Wpla-",
        "esUX5Wmo2zr0",
        "uNVh7i2s2rj_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurst38/deep_learning/blob/main/Utilisation_des_CNNs_avec_Keras_sur_des_donn%C3%A9es_d'expression_faciale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7meu-pps3QMc"
      },
      "source": [
        "# Utilisation des CNNs avec Keras sur des données d'expression faciale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-diCsctWfSh"
      },
      "source": [
        "## Vérification de l'utilisation de GPU\n",
        "\n",
        "Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S9vf7TtjjMa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifgZIuXxPc57"
      },
      "source": [
        "## Téléchargement du dataset d'expressions faciales depuis un repo git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nh2my7ePd6G"
      },
      "source": [
        "!git clone https://github.com/muxspace/facial_expressions.git\n",
        "!ls \n",
        "!head facial_expressions/data/legend.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_vshNHAPj6y"
      },
      "source": [
        "## Import de TensorFlow et des autres librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDqlPGuPVuZn"
      },
      "source": [
        "import itertools\n",
        "import pathlib\n",
        "import typing\n",
        "\n",
        "import cv2\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import pandas\n",
        "import seaborn\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.utils\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glVauu2SkG1A"
      },
      "source": [
        "## Chargement des données\n",
        "\n",
        "*Après une rapide étude du dataset à l'aide de commandes usuelles du terminal, implémentez les fonctions de chargement du dataset. Vous pourrez utiliser [`pandas.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) pour charger un CSV dans une [`pandas.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eDbOBSHkuSw"
      },
      "source": [
        "# Votre code ici\n",
        "def load_data(csv_path: pathlib.Path, shuffle: bool = True\n",
        "             ) -> typing.Tuple[numpy.ndarray, numpy.ndarray]:\n",
        "  return numpy.array([]), numpy.array([])\n",
        "\n",
        "\n",
        "images, labels = load_data(\n",
        "    pathlib.Path(\"facial_expressions\") / \"data\" / \"legend.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj7vdViMlF3D"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBDzE-s_SRwP"
      },
      "source": [
        "label_names = [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happiness\", \"sadness\",\n",
        "               \"surprise\", \"neutral\"]\n",
        "label_to_index = {l: i for i, l in enumerate(label_names)}\n",
        "\n",
        "\n",
        "image_dir_path = pathlib.Path(\"facial_expressions\") / \"images\"\n",
        "\n",
        "\n",
        "def load_image(filename: str) -> numpy.ndarray:\n",
        "    image = cv2.imread(str(image_dir_path / filename))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return cv2.resize(image, (150, 150))\n",
        "\n",
        "\n",
        "def load_data(csv_path: pathlib.Path, shuffle: bool = True\n",
        "             ) -> typing.Tuple[numpy.ndarray, numpy.ndarray]:\n",
        "  df = pandas.read_csv(csv_path)\n",
        "  images = numpy.stack(df[\"image\"].map(load_image))\n",
        "  labels = df[\"emotion\"].map(label_to_index).to_numpy(dtype=numpy.int8)\n",
        "  if shuffle:\n",
        "    images, labels = sklearn.utils.shuffle(images, labels)\n",
        "  return images, labels\n",
        "\n",
        "\n",
        "# load_data(pathlib.Path(\"facial_expressions\") / \"data\" / \"legend.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf2HIPYfk0WX"
      },
      "source": [
        "images, labels = load_data(\n",
        "    pathlib.Path(\"facial_expressions\") / \"data\" / \"legend.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HSxBIIXlMZJ"
      },
      "source": [
        "## Exploration du dataset\n",
        "\n",
        "*Affichez les caractéristiques du dataset suivantes :*\n",
        "\n",
        "- *La taille des données*\n",
        "- *Le nombre d'exemple dans chaque classe*\n",
        "- *Quelques exemples annotés*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6v_F-lkj0r"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CplV6KtynBbQ"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFJJLHSYzBYM"
      },
      "source": [
        "print(f\"Forme des images : {images.shape}\")\n",
        "print(f\"Forme des labels : {labels.shape}\")\n",
        "\n",
        "\n",
        "def plot_label_counts(labels: numpy.ndarray) -> None:\n",
        "  # Plot des décomptes sur la grande figure\n",
        "  ax = seaborn.countplot(x=labels)\n",
        "  ax.set_title(\"Décomptes des différents labels\")\n",
        "  ax.set_ylabel(\"Décompte\")\n",
        "  ax.set_xlabel(\"Label\")\n",
        "  ax.set_xticklabels(label_names, rotation=15)\n",
        "  plt.show()\n",
        "\n",
        "  # Récupération des décomptes de chaque label\n",
        "  _, counts = numpy.unique(labels, return_counts=True)\n",
        "\n",
        "  # Création d'une pandas.DataFrame pour affichage\n",
        "  df_counts = pandas.DataFrame({\"label\": sorted(label_to_index.values()),\n",
        "                                \"décompte\": counts},\n",
        "                              index=label_names)\n",
        "  # Ajout d'une colonne avec les pourcentages\n",
        "  df_counts[\"pourcentage\"] = (df_counts[\"décompte\"] * 100\n",
        "                              / df_counts[\"décompte\"].sum())\n",
        "  IPython.core.display.display(df_counts)\n",
        "\n",
        "\n",
        "plot_label_counts(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mERY5RUoeCLy"
      },
      "source": [
        "# Création de la grille de sous-plots. On donne l'argument figsize pour agrandir\n",
        "# la taille de la figure qui est petite par défaut\n",
        "f, ax = plt.subplots(5, 5, figsize=(15, 15))\n",
        "\n",
        "# On choisit 25 indices au hasard, sans replacement (on ne veut pas afficher la\n",
        "# même image deux fois)\n",
        "random_indexes = numpy.random.choice(images.shape[0],\n",
        "                                     size=(5, 5),\n",
        "                                     replace=False)\n",
        "\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "    # Récupération de l'image et du label\n",
        "    img_index = random_indexes[i, j]\n",
        "    image = images[img_index]\n",
        "    label = label_names[labels[img_index]]\n",
        "\n",
        "    # Affichage avec matplotlib et sa fonction imshow, très pratique en vision par\n",
        "    # ordinateur\n",
        "    ax[i, j].imshow(image)\n",
        "    ax[i, j].set_title(f\"Exemple {img_index} ({label})\")\n",
        "    ax[i, j].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBbfuELPnnVn"
      },
      "source": [
        "## Séparation train/test\n",
        "\n",
        "Pour pouvoir évaluer notre modèle, il faut mettre de côté une partie des données. On ne les utilisera pas pendant l'apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9JQ6LiwNC47"
      },
      "source": [
        "# Séparation en train et test (la séparation en train/valid est faite\n",
        "# automatiquement dans model.fit())\n",
        "# On fera une séparation 80/20 en respectant les proportions des classes\n",
        "train_images, test_images, train_labels, test_labels = (\n",
        "    sklearn.model_selection.train_test_split(images,\n",
        "                                             labels,\n",
        "                                             test_size=0.2,\n",
        "                                             stratify=labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbNJmMGDn3PF"
      },
      "source": [
        "## Apprentisage\n",
        "\n",
        "- *Définissez un modèle*\n",
        "- *Entraînez votre modèle avec `model.fit(…)`*\n",
        "- *Affichez vos courbes d'apprentissage*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kLOvELXoP6I"
      },
      "source": [
        "# Votre code ici\n",
        "model = keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z0x2FNEory5"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-FOMeXsWIjV"
      },
      "source": [
        "def build_model() -> keras.models.Model:\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "  conv2d_params = dict(activation=\"relu\", kernel_size=(3, 3))\n",
        "\n",
        "  model.add(keras.layers.Input(shape=(150, 150, 3)))\n",
        "  model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "  model.add(keras.layers.Conv2D(200, **conv2d_params))\n",
        "  model.add(keras.layers.MaxPool2D(5, 5))\n",
        "  model.add(keras.layers.Conv2D(50, **conv2d_params))\n",
        "  model.add(keras.layers.Conv2D(50, **conv2d_params))\n",
        "  model.add(keras.layers.MaxPool2D(3, 3))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dense(50, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dropout(rate=0.5))\n",
        "  model.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# Affichage d'un résumé du modèle\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcAw5roAxeKj"
      },
      "source": [
        "# Apprentissage du modèle\n",
        "checkpoint_filepath = \"unweighted-checkpoint\"\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    save_best_only=True)\n",
        "\n",
        "training = model.fit(train_images,\n",
        "                     train_labels,\n",
        "                     epochs=10,\n",
        "                     validation_split=0.30,\n",
        "                     callbacks=[model_checkpoint_callback],\n",
        "                     batch_size=32)\n",
        "\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "# Plot des métriques d'entraînement\n",
        "def plot_metrics(history) -> None:\n",
        "  plt.plot(training.history[\"accuracy\"])\n",
        "  plt.plot(training.history[\"val_accuracy\"])\n",
        "  plt.title(\"Accuracy du modèle\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper left\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(training.history[\"loss\"])\n",
        "  plt.plot(training.history[\"val_loss\"])\n",
        "  plt.title(\"Perte du modèle\")\n",
        "  plt.ylabel(\"Perte\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Entraînement\", \"Validation\"], loc=\"upper right\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_metrics(training.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvXQHYY9oyrb"
      },
      "source": [
        "## Évaluation des performances en test\n",
        "\n",
        "*Utilisez `model.evaluate(…)` pour mesurer les performances de votre modèle sur l'ensemble de test.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8MQxeGwo4h9"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq8vcEL8o78Z"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnolebbDLkH-"
      },
      "source": [
        "model.evaluate(test_images, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxFZ0wrCpApj"
      },
      "source": [
        "## Calcul et affichage de la matrice de confusion\n",
        "\n",
        "*Utilisez [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) pour calculer la matrice de confusion de votre modèle sur les données de test, puis utilisez [`seaborn.heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) pour l'afficher.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5JXgtkdpjZj"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4jMT76Wpla-"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgdfBwdZdze8"
      },
      "source": [
        "def evaluate(model: keras.models.Model,\n",
        "             images: numpy.ndarray,\n",
        "             labels: numpy.ndarray\n",
        "            ) -> None:\n",
        "  model.evaluate(images, labels, verbose=1)\n",
        "  predictions = numpy.argmax(model.predict(images), axis=-1)\n",
        "  confusion_matrix = sklearn.metrics.confusion_matrix(predictions,\n",
        "                                                      labels,\n",
        "                                                      normalize=\"true\")\n",
        "  seaborn.heatmap(confusion_matrix,\n",
        "                  cmap=\"rocket_r\",\n",
        "                  xticklabels=label_names,\n",
        "                  yticklabels=label_names,\n",
        "                  annot=True,\n",
        "                  fmt=\".2f\")\n",
        "  plt.title(\"Matrice de confusion\")\n",
        "  plt.show()\n",
        "\n",
        "  plot_label_counts(labels)\n",
        "\n",
        "\n",
        "evaluate(model, test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyXmbpFDsLh_"
      },
      "source": [
        "## Avec des pondération pour les classes\n",
        "\n",
        "Il est possible de donner un argument `class_weight` à `model.fit`. Cet argument correspond à un facteur multiplicatif dans la loss à appliquer au score de chaque classe.\n",
        "\n",
        "*Utilisez [`sklearn.utils.class_weight.compute_class_weight`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) pour calculer les poids à attribuer à chaque classe.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sHnihoAqfR4"
      },
      "source": [
        "class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
        "    \"balanced\", numpy.unique(train_labels), train_labels)\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4HUpU_C2OSa"
      },
      "source": [
        "## Clipping des pondérations\n",
        "\n",
        "Dans un premier temps, il peut être intéressant de vérifier que les poids de classe améliorent les performances du modèle pour les classes sous-représentées sans utiliser toutefois des pondérations trop fortes.\n",
        "\n",
        "*Utilisez [`numpy.clip`](https://numpy.org/doc/stable/reference/generated/numpy.clip.html) pour restreindre les valeurs des pondérations à $[0, 5]$.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6tfzJsF2y2k"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esUX5Wmo2zr0"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQfnyUk6hJdr"
      },
      "source": [
        "numpy.clip(class_weights, None, 5, out=class_weights)\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VGaWFeI2jbA"
      },
      "source": [
        "## Utilisation des pondérations\n",
        "\n",
        "*Re-contruisez votre modèle et entraînez le avec les pondérations calculées, puis évaluez-le.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAA7sUyP2qlO"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNVh7i2s2rj_"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd7qgFW5r3Wp"
      },
      "source": [
        "# Construction du modèle\n",
        "model = build_model()\n",
        "\n",
        "# Apprentissage du modèle\n",
        "training = model.fit(train_images,\n",
        "                     train_labels,\n",
        "                     epochs=20,\n",
        "                     validation_split=0.3,\n",
        "                     class_weight={c: w for c, w in enumerate(class_weights)},\n",
        "                     batch_size=32)\n",
        "\n",
        "plot_metrics(training.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JbdlLNyuNRs"
      },
      "source": [
        "evaluate(model, test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}