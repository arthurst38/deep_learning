{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auto-encodeurs débruiteurs avec Keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "gRYZYnM9XUTS",
        "KpejbvhkYn0Z",
        "Q6zfB8OzZNEf",
        "A2kujXqBzxG2",
        "JhhNytD9z8DQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurst38/deep_learning/blob/main/Auto_encodeurs_d%C3%A9bruiteurs_avec_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG3FpzjPt0xr"
      },
      "source": [
        "# Auto-encodeurs débruiteurs avec Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwA9xMdHt4sb"
      },
      "source": [
        "## Vérification de l'utilisation de GPU\n",
        "\n",
        "Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeXU4lw0TGQq"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4zy4V2h2d4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NgbfFbJt_V5"
      },
      "source": [
        "## Import de TensorFlow et des autres librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5OnIl-BHSfx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3BhjGTdLz_e"
      },
      "source": [
        "## Chargement de MNIST\n",
        "\n",
        "Nous allons utiliser un prétraîtement légèrement différent des autres fois : étant donné que nous voulons pouvoir prédire les valeurs données en entrée en sortie (principe de l'auto-encodage), nous allons simplement projeter ces valeurs dans $[0, 1]$ au lieu de $[0, 255]$. Notez qu'habituellement nous ne faisons pas ça : nous normalisons en centrant sur zéro et en divisant par l'écart-type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzmZuz_HIVO0"
      },
      "source": [
        "(X_train, _), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "nb_classes = 10\n",
        "input_dim = 28 * 28\n",
        "X_train = X_train.reshape(-1, input_dim).astype('float32')\n",
        "X_test = X_test.reshape(-1, input_dim).astype('float32')\n",
        "\n",
        "# On utilise cette normalisation pour garder les pixel à 0 où ils sont\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsR_fKX3dOnF"
      },
      "source": [
        "## Application d'un bruit  gaussien"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRKjObLvdH-Z"
      },
      "source": [
        "noise_factor = 0.5\n",
        "X_train_noisy = X_train + numpy.random.normal(0, noise_factor, X_train.shape) \n",
        "X_test_noisy = X_test + numpy.random.normal(0, noise_factor, X_test.shape)\n",
        "\n",
        "# On clip les valeurs pour éviter les pixels plus blanc que blanc (ou plus noir\n",
        "# que noir) \n",
        "numpy.clip(X_train_noisy, 0, 1, out=X_train_noisy)\n",
        "numpy.clip(X_test_noisy, 0, 1, out=X_test_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgKpN7EsdtVc"
      },
      "source": [
        "n = 10\n",
        "f, ax = plt.subplots(1, n, figsize=(n * 1.4, 2))\n",
        "for i in range(n):\n",
        "    ax[i].imshow(X_test_noisy[i].reshape(28, 28), cmap=\"gray_r\")\n",
        "    ax[i].set_title(y_test[i])\n",
        "    ax[i].axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi0dZwTvL74R"
      },
      "source": [
        "## Création de l'autoencodeur débruiteur\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEktY3zWXGBr"
      },
      "source": [
        "# Votre code ici\n",
        "encoding_dim = 4\n",
        "model = keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRYZYnM9XUTS"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K9FKmjWR5x6"
      },
      "source": [
        "encoding_dim = 4\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Input(shape=input_dim))\n",
        "model.add(keras.layers.Dense(encoding_dim, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(input_dim, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpfqqlI-Xh5N"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "*Écrivez la ligne correspondant à l'apprentissage de votre autoencodeur :*\n",
        "\n",
        "- *50 itérations devraient suffire*\n",
        "- *Utilisez un batch de 256*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e457ISDiYnzn"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpejbvhkYn0Z"
      },
      "source": [
        "##Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7eEjwwEIYFU"
      },
      "source": [
        "model.fit(X_train_noisy, X_train,\n",
        "          epochs=50,\n",
        "          batch_size=256,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWbYZXb6YwhM"
      },
      "source": [
        "## Base de Test\n",
        "\n",
        "Autoencodez les images de test et stockez les images obtenues dans la variable `decoded_imgs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0E47nRZND-"
      },
      "source": [
        "# Votre code ici\n",
        "decoded_imgs = X_test_noisy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6zfB8OzZNEf"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNPXO2JXIalg"
      },
      "source": [
        "decoded_imgs = model.predict(X_test_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7KLWxZpZZWp"
      },
      "source": [
        "## Affichage visuel de la performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elXKC4kxIexp"
      },
      "source": [
        "n = 10\n",
        "f, ax = plt.subplots(2, n, figsize=(n * 1.4, 4))\n",
        "for i in range(n):\n",
        "    # L'original en haut\n",
        "    ax[0, i].imshow(X_test_noisy[i].reshape(28, 28), cmap=\"gray_r\")\n",
        "    ax[0, i].set_title(str(y_test[i]))\n",
        "    ax[0, i].axis(\"off\")\n",
        "\n",
        "    # La reconstruction en bas\n",
        "    ax[1, i].imshow(decoded_imgs[i].reshape(28, 28), cmap=\"gray_r\")\n",
        "    ax[1, i].axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhlicf7oZ3wl"
      },
      "source": [
        "## Essayez avec plus de neurones\n",
        "\n",
        "Que se passe-t-il ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zluxB_On8ca"
      },
      "source": [
        "## Utilisation des réseaux convolutifs\n",
        "\n",
        "Pour cela il faut remettre chaque image sous forme 28x28x1. Les CNNs ont besoin de cette 3ème dimension de tenseur (il pourrait y avoir plus de canaux que le niveau de gris : il y en a 3 pour les images en couleur et plus encore dans les couches intermédiaires d'un réseau convolutif où le nombre de canaux en entrée d'une couche sera le nombre de kernels de la couche précédente)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LcXRU-ooX9c"
      },
      "source": [
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "X_train_noisy = X_train_noisy.reshape(-1, 28, 28, 1)\n",
        "X_test_noisy = X_test_noisy.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHLn3Y0bxP1g"
      },
      "source": [
        "## Création du modèle\n",
        "\n",
        "On utilisera des séquences de Conv2D,MaxPool2D avec des kernel de respectivement 3x3 et 2x2 pour la partie encodeur. Dans ces deux layers, il faudra utiliser l'option \"padding='same'\" afin d'éviter les effets de bord (l'image étant déjà assez petite comme ça).\n",
        "\n",
        "Pour la partie decodeur, on utilisera des Conv2D de même nature suivis par des UpSampling2D((2,2)) qui correspond à l'opération 'inverse' de MaxPool2D\n",
        "\n",
        "N'hésitez pas à abuser de model.summary() pour vous y retrouver. L'objectif étant de retrouver une image 28x28x1 à la sortie du dernier Conv2D. En effet, finir par un Upsampling2D serait une mauvaise idée.\n",
        "\n",
        "Le réseau va être profond, on utilisera des fonctions d'activation relu, sauf pour la dernière où on utilisera une sigmoïde."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySGG5N5CzJLd"
      },
      "source": [
        "# Votre code ici\n",
        "model = keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2kujXqBzxG2"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXSUNJ_5pbFe"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "# Couches d'encodage\n",
        "model.add(keras.layers.Input(shape=X_train.shape[1:]))\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(keras.layers.MaxPool2D((2, 2), padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(keras.layers.MaxPool2D((2, 2), padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "\n",
        "# Couches de décodage\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(keras.layers.UpSampling2D((2, 2)))\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(keras.layers.UpSampling2D((2, 2)))\n",
        "model.add(keras.layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz2V4Enzz8CX"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "*Écrivez la ligne correspondant à l'apprentissage de votre autoencodeur :*\n",
        "\n",
        "- *100 itérations devraient suffire*\n",
        "- *Utilisez un batch de 256*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YeaMCqyz8Cw"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhhNytD9z8DQ"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQ9JhPDqVtD"
      },
      "source": [
        "model.fit(X_train_noisy, X_train,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDoOAPbOzaMW"
      },
      "source": [
        "## Affichage des performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1zvzPqQtqgy"
      },
      "source": [
        "decoded_imgs = model.predict(X_test_noisy).reshape(-1, 28, 28)\n",
        "\n",
        "n = 10\n",
        "f, ax = plt.subplots(2, n, figsize=(n * 1.4, 4))\n",
        "\n",
        "random_indexes = numpy.random.choice(X_test.shape[0],\n",
        "                                     replace=False,\n",
        "                                     size=n)\n",
        "\n",
        "for i, random_index in enumerate(random_indexes):\n",
        "    # L'image originale en haut\n",
        "    ax[0, i].set_title(str(y_test[random_index]))\n",
        "    ax[0, i].imshow(X_test_noisy[random_index].reshape(28, 28), cmap=\"gray_r\")\n",
        "    ax[0, i].axis(\"off\")\n",
        "\n",
        "    # L'image reconstruite en bas\n",
        "    ax[1, i].imshow(decoded_imgs[random_index], cmap=\"gray_r\")\n",
        "    ax[1, i].axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiOFCmhbudGD"
      },
      "source": [
        "## Sur des images non-bruitées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1FGetiyMdxh"
      },
      "source": [
        "decoded_imgs = model.predict(X_test).reshape(-1, 28, 28)\n",
        "\n",
        "n = 10\n",
        "f, ax = plt.subplots(2, n, figsize=(n * 1.4, 4))\n",
        "\n",
        "random_indexes = numpy.random.choice(X_test.shape[0],\n",
        "                                     replace=False,\n",
        "                                     size=n)\n",
        "\n",
        "for i, random_index in enumerate(random_indexes):\n",
        "    # L'image originale en haut\n",
        "    ax[0, i].set_title(str(y_test[random_index]))\n",
        "    ax[0, i].imshow(X_test[random_index].reshape(28, 28), cmap=\"gray_r\")\n",
        "    ax[0, i].axis(\"off\")\n",
        "\n",
        "    # L'image reconstruite en bas\n",
        "    ax[1, i].imshow(decoded_imgs[random_index], cmap=\"gray_r\")\n",
        "    ax[1, i].axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}