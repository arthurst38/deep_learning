{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Génération de texte - RNN - Keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurst38/deep_learning/blob/main/G%C3%A9n%C3%A9ration_de_texte_RNN_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7DffJ5GQxMm"
      },
      "source": [
        "# Modèle de langage et génération de séquence\n",
        "\n",
        "Ce TP a pour but de vous familiariser avec le concept de modèle de langage et de génération de séquence.\n",
        "\n",
        "À partir d'un corpus de textes écrits par Voltaire, nous allons apprendre un modèle récurrent basé sur les séquences de caractères."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOmx0imcNPA6"
      },
      "source": [
        "## Vérification de l'utilisation de GPU\n",
        "\n",
        "Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC54YGM3c4dK"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEJ3HnfXRZJn"
      },
      "source": [
        "## Récupération des données\n",
        "\n",
        "Les différents texte de Voltaire qui constituent le corpus ont été obtenus à partir de gutenberg.org. Les headers, footers ainsi que les préfaces ont été préalablement enlevés : on ne voudrait pas que notre modèle de langage apprenne à écrire les disclaimers de gutenberg.org ou les préface de l'éditeur.\n",
        "\n",
        "On utilisera uniquement le fichier `dataset-voltaire/voltaire_clean.txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7cHjomvYCJH"
      },
      "source": [
        "!rm -rf dataset-voltaire\n",
        "!git clone https://github.com/nzmonzmp/dataset-voltaire.git\n",
        "print(\"─\" * 50)\n",
        "!ls -l dataset-voltaire/\n",
        "print(\"─\" * 50)\n",
        "!cat dataset-voltaire/voltaire_clean.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC_1XEf-RAyd"
      },
      "source": [
        "# Utilisez cette cellule pour explorer un peu les données.\n",
        "!wc dataset-voltaire/voltaire_clean.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q45KSSLErfKg"
      },
      "source": [
        "# Décommentez pour télécharger le fichier\n",
        "# import google.colab\n",
        "# google.colab.files.download('dataset-voltaire/concat_voltaire.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wnc7j6IS5wN"
      },
      "source": [
        "## Import de TensorFlow et des autres librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbRE-dA1YIbq"
      },
      "source": [
        "import numpy\n",
        "import pathlib\n",
        "import typing\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RADGquLfTQcj"
      },
      "source": [
        "## Chargement des données et extraction du vocabulaire\n",
        "\n",
        "- *Chargez le texte du ficher en miniscules dans la variable `text`*\n",
        "- *Extrayez tous les caractères utilisés dans `text` dans la liste `index_to_char`, triés par ordre alphabétique. Cette liste sert pour passer de la représentation numérique d'un caractère au caractère lui-même*\n",
        "- *Construisez un dictionnaire `char_to_index` qui va permettre de passer d'un caractère à sa représentation numérique*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS8A_kvYT8kS"
      },
      "source": [
        "text = \"toto\"\n",
        "index_to_char = [\"o\", \"t\"]\n",
        "char_to_index = {\"o\": 0, \"t\": 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuuZawPFUs9D"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxOwfa8YZR4"
      },
      "source": [
        "text = pathlib.Path(\"dataset-voltaire/voltaire_clean.txt\").read_text().lower()\n",
        "print(f\"{text[:100]}…\")\n",
        "print(f\"Nombre de caractères : {len(text)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-FRYzYpvR_P"
      },
      "source": [
        "index_to_char = sorted(set(text))\n",
        "print(index_to_char)\n",
        "print(f\"Taille du dictionnaire : {len(index_to_char)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYzPxBs6znsb"
      },
      "source": [
        "char_to_index = {c: i for i, c in enumerate(index_to_char)}\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkKw4--AVCyR"
      },
      "source": [
        "## Prétraitements\n",
        "\n",
        "Découpage du texte en séquences de 30 caractères, tous les 3 caractères. Les cibles seront les 31èmes caractères"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AmeP1QXzz8y"
      },
      "source": [
        "maxlen = 30\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(f\"Nombre de séquences : {len(sentences)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du82K8bmO1dU"
      },
      "source": [
        "print(sentences[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcs0XeYTWUip"
      },
      "source": [
        "## Création des tableaux d'entrée et de sortie\n",
        "\n",
        "*Créez les variables `X` et `y` qui contiennent les données d'entrée et de sortie encodées.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIPAgXBtRVaA"
      },
      "source": [
        "# Votre code ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukEy_wBrRWSv"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_49570RnxQMk"
      },
      "source": [
        "def encode(sentence: str) -> numpy.ndarray:\n",
        "  return numpy.array([char_to_index[char] for char in sentence])\n",
        "\n",
        "\n",
        "X = numpy.vstack(map(encode, sentences))\n",
        "y = numpy.array(encode(next_chars))\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfg2hk5yXDHL"
      },
      "source": [
        "## Préparation du modèle\n",
        "\n",
        "*Essayez différents modèles ([`LSTM`](https://keras.io/api/layers/recurrent_layers/lstm/), [`GRU`](https://keras.io/api/layers/recurrent_layers/gru/), [`SimpleRNN`](https://keras.io/api/layers/recurrent_layers/simple_rnn/)) de différentes tailles.*\n",
        "\n",
        "*Laissez quelques itérations à l'algorithme avant d'essayer une nouvelle configuration, ou utilisez [Keras Tuner](https://keras-team.github.io/keras-tuner/) pour le faire automatiquement.*\n",
        "\n",
        "L'objectif étant évidemment de minimiser la loss : Plus elle est basse, plus le modèle est proche du modèle de langage de Voltaire.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVyLVMBj2rCx"
      },
      "source": [
        "def build_model(embedding_dim: int = 8,\n",
        "                lstm_hidden_dim: int = 128,\n",
        "                learning_rate: float = 1e-3\n",
        "               ) -> keras.models.Model:\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Embedding(len(index_to_char), embedding_dim))\n",
        "  model.add(keras.layers.LSTM(lstm_hidden_dim))\n",
        "  model.add(keras.layers.Dense(len(index_to_char), activation=\"softmax\"))\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOdG3rJ3XjCX"
      },
      "source": [
        "## Génération de texte\n",
        "\n",
        "On génère dans le code qui suit les caractères un à un, en décalant progressivement l'entrée donnée pour qu'elle fasse toujours `maxlen` caractères.\n",
        "\n",
        "`tf.random.categorical` permet d'échantillonner depuis une distribution de probabilité, c'est donc notre outil principal pour exploiter la sortie du réseau : le softmax définit en effet une telle distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xABJru-m7_7r"
      },
      "source": [
        "def sample(n_steps: int = 200):\n",
        "  start_index = numpy.random.randint(0, len(text) - maxlen - 1)\n",
        "  sentence = text[start_index:start_index + maxlen]\n",
        "  print(\"─\" * 50)\n",
        "  print(f\"Génération à partir de : « {sentence} »\")\n",
        "  print(\"─\" * 50)\n",
        "  print(sentence, end=\"\")\n",
        "\n",
        "  for _ in range(n_steps):\n",
        "    word_probas = model.predict(encode(sentence)[None, :], verbose=0)\n",
        "    next_index = tf.random.categorical(tf.math.log(word_probas), 1)[0][0]\n",
        "    next_char = index_to_char[next_index]\n",
        "    sentence = sentence[1:] + next_char\n",
        "    print(next_char, end=\"\")\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j0kcANosgOu"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "Plutôt que de générer toutes les `EPOCHS` epochs comme on le fait là à l'aide d'une boucle extérieure, on aurait aussi pu utiliser un [callback Keras](https://keras.io/api/callbacks/lambda_callback/), mais on ne souhaite pas générer à toutes les epochs et cette façon de faire est donc dans ce cas plus pratique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUdzOmL68WsZ"
      },
      "source": [
        "EPOCHS = 10\n",
        "model = build_model()\n",
        "for i in range(10):\n",
        "  model.fit(X, y,\n",
        "            batch_size=4096,\n",
        "            epochs=EPOCHS)\n",
        "  print()\n",
        "  print(\"─\" * 50)\n",
        "  print(f\"Après {(i + 1) * EPOCHS} epochs :\")\n",
        "  sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKtzISsI6fJM"
      },
      "source": [
        "## Une solution avec plusieurs couches de LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_ST_NeJUPZo"
      },
      "source": [
        "def build_deep_model(embedding_dim: int = 8,\n",
        "                     lstm_hidden_dim: int = 128,\n",
        "                     learning_rate: float = 1e-3\n",
        "                    ) -> keras.models.Model:\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Embedding(len(index_to_char), embedding_dim))\n",
        "  model.add(keras.layers.LSTM(lstm_hidden_dim, return_sequences=True))\n",
        "  model.add(keras.layers.LSTM(lstm_hidden_dim))\n",
        "  model.add(keras.layers.Dense(len(index_to_char), activation=\"softmax\"))\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fghrKgmbUU74"
      },
      "source": [
        "EPOCHS = 10\n",
        "model = build_deep_model()\n",
        "for i in range(10):\n",
        "  model.fit(X, y,\n",
        "            batch_size=4096,\n",
        "            epochs=EPOCHS)\n",
        "  print()\n",
        "  print(\"─\" * 50)\n",
        "  print(f\"Après {(i + 1) * EPOCHS} epochs :\")\n",
        "  sample()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}