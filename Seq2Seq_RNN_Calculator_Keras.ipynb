{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq - RNN Calculator - Keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "nu5vJT1zjDu0"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurst38/deep_learning/blob/main/Seq2Seq_RNN_Calculator_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9yjgkZDh6JU"
      },
      "source": [
        "# Utilisation des RNNs avec Keras sur des équations mathématiques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz9-z0pbiB5g"
      },
      "source": [
        "## Vérification de l'utilisation de GPU\n",
        "\n",
        "Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqWSq1v8U2qi"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhFpJ09ciFtO"
      },
      "source": [
        "## Import de TensorFlow et des autres librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QsX1xPMx0y-"
      },
      "source": [
        "import operator\n",
        "import random\n",
        "import typing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import seaborn\n",
        "import sklearn.model_selection\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS3irsR_iI5q"
      },
      "source": [
        "## Définition du vocabulaire\n",
        "\n",
        "Dans ces travaux pratiques, nous allons définir des équations, comme `3 + 1 = 4`. Le modèle devra prédire `4` avec comme entrée `3 + 1`.\n",
        "\n",
        "Pour commencer, créons le vocabulaire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "085nDjw0ziTY"
      },
      "source": [
        "operations = list(\"+*-/\")\n",
        "numbers = list(\"0123456789.\")\n",
        "padding = [\" \"]\n",
        "\n",
        "index_to_char = numbers + operations + padding\n",
        "char_to_index = {c: i for i, c in enumerate(index_to_char)}\n",
        "\n",
        "print(f\"Index vers caractère : {index_to_char}\")\n",
        "print(f\"Caractère vers index : {char_to_index}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n41x5K-ib7m"
      },
      "source": [
        "## Utilisation du vocabulaire pour encoder et décoder des équations\n",
        "\n",
        "Nous pouvons maintenant utiliser ce vocabulaire pour transformer des équations textuelles en suite de chiffres, compréhensibles par un réseau de neurones :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzrJ3sEiilMH"
      },
      "source": [
        "def encode(characters: str) -> numpy.ndarray:\n",
        "  return numpy.array([char_to_index[char] for char in characters])\n",
        "\n",
        "\n",
        "def decode(array: numpy.ndarray):\n",
        "  return ''.join(index_to_char[i] for i in array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMu9Hhf2iw3j"
      },
      "source": [
        "*Testez les fonctions `encode` et `decode`. Pensez-vous que le réseau de neurones pourra travailler directement sur la sortie de `encode` ou faudra-t-il appliquer un prétraitement supplémentaire ?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KlIgmFljATs"
      },
      "source": [
        "# Votre code de test ici"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk_DVL0-jCjU"
      },
      "source": [
        "Votre réponse ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu5vJT1zjDu0"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuICYDdGjE26"
      },
      "source": [
        "equation = \"3/4+2-5\"\n",
        "result = \"0\"\n",
        "print(\"─\" * 50)\n",
        "print(\"Équation\")\n",
        "print(\"─\" * 50)\n",
        "print(f\"Forme brute       {equation}\")\n",
        "print(f\"Encodage          {encode(equation)}\")\n",
        "print(f\"Encodage/décodage {decode(encode(equation))}\")\n",
        "print()\n",
        "print(\"─\" * 50)\n",
        "print(\"Résultat\")\n",
        "print(\"─\" * 50)\n",
        "print(f\"Forme brute       {result}\")\n",
        "print(f\"Encodage          {encode(result)}\")\n",
        "print(f\"Encodage/décodage {decode(encode(result))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cDsM-YXl-1Y"
      },
      "source": [
        "Cet encodage est insuffisant pour le traitement par des réseaux de neurones : il faudra au choix one-hot encoder en sus ou passer par une couche d'embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZL7bqUllqVc"
      },
      "source": [
        "## Génération de données\n",
        "\n",
        "Nous pouvons maintenant procéder à la génération d'exemples, qui serviront pour l'entraînement, la validation et le test.\n",
        "\n",
        "Pour faire cela, nous allons sélectionner aléatoirement une opération parmi les 4 définies et générer des entiers aléatoires pour appliquer cette opération. Ce processus sera répété jusqu'à atteindre le nombre souhaité d'exemples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF0CYjZwznU7"
      },
      "source": [
        "def make_maths_problem(n_samples=1000,\n",
        "                       n_digits=3,\n",
        "                       invert=True):\n",
        "  equations = []\n",
        "  results = []\n",
        "  \n",
        "  math_operation = {\"+\": operator.add, \n",
        "                    \"-\": operator.sub,\n",
        "                    \"*\": operator.mul,\n",
        "                    \"/\": operator.truediv}\n",
        "\n",
        "  # Taille maximale que peut faire la chaîne décrivant l'opération\n",
        "  max_equation_len = 2 * n_digits + 1\n",
        "  max_result_len = 2 * n_digits\n",
        "\n",
        "  while len(equations) < n_samples:\n",
        "    # Sélection d'une opération aléatoire\n",
        "    operation = numpy.random.choice(operations)\n",
        "\n",
        "    # Génération de deux entiers qui respectent la limite de taille\n",
        "    left, right = numpy.random.randint(10 ** n_digits, size=2)\n",
        "\n",
        "    equation = f\"{left}{operation}{right}\"\n",
        "\n",
        "    if equation not in equations:\n",
        "      # Calcul du résultat. Étant donné que left et right sont des entiers\n",
        "      # numpy, ce calcul ne cause pas d'exception, même en cas de division par 0\n",
        "      math_result = math_operation[operation](left, right)\n",
        "\n",
        "      # On recommence si le résultat n'est pas exploitable\n",
        "      if math_result == numpy.inf or numpy.isnan(math_result):\n",
        "        continue\n",
        "\n",
        "      # Le résultat peut-être très grand (0.3333333…), on limite sa taille\n",
        "      result = str(math_result)[:max_result_len]\n",
        "\n",
        "      # On « pad » pour que toutes les séquences fassent la même taille\n",
        "      padded_equation = equation.ljust(max_equation_len)\n",
        "      padded_result = result.ljust(max_result_len)\n",
        "\n",
        "      # On inverse si l'argument invert est donné\n",
        "      if invert:\n",
        "        padded_equation = padded_equation[::-1]\n",
        "\n",
        "      equations.append(padded_equation)\n",
        "      results.append(padded_result)\n",
        "  \n",
        "  X = numpy.array(list(map(encode, equations)))\n",
        "  y = numpy.array(list(map(encode, results)))\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBMg52C9oL1n"
      },
      "source": [
        "Testons cette fonction avec une dizaine d'exemples :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH2d_NLpzqi5"
      },
      "source": [
        "X, y = make_maths_problem(10, n_digits=3)\n",
        "\n",
        "print(f\"Forme de X : {X.shape}\")\n",
        "print(f\"Forme de y : {y.shape}\")\n",
        "\n",
        "print()\n",
        "print(\"Quelques exemples générés\")\n",
        "for encoded_equation, encoded_result in zip(X, y):\n",
        "    # Par défault l'inversion des équations est activée, il faut la défaire\n",
        "    # pour pouvoir visualiser l'équation originale\n",
        "    equation = decode(encoded_equation[::-1])\n",
        "    result = decode(encoded_result)\n",
        "    print(f\"{equation} = {result}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M02S_csCoeLU"
      },
      "source": [
        "Nous pouvons maintenant créer le dataset et les splits nécessaires :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u8uqaUTzycf"
      },
      "source": [
        "X, y = make_maths_problem(100_000, n_digits=3)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    X, y, train_size=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muyhYvUWoi89"
      },
      "source": [
        "## Définition du modèle\n",
        "\n",
        "Pour traiter ces séquences de caractères, nous allons utiliser un RNN. Comme dit auparavant, il sera nécessaire de one-hot encoder les séquences d'entrée ou de les passer par une couche d'embeddings. Ici, nous utiliserons la couche d'embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyhYMw_Wz6NS"
      },
      "source": [
        "def rnn_model(hidden_size=1024, n_digits=3):\n",
        "  model = keras.models.Sequential()\n",
        "  # Encodeur\n",
        "  model.add(keras.layers.Embedding(len(index_to_char), 16))\n",
        "  model.add(keras.layers.GRU(hidden_size, return_sequences=True))\n",
        "  model.add(keras.layers.GRU(hidden_size))\n",
        "  \n",
        "  # Décodeur\n",
        "  # La couche RepeatVector permet de dupliquer la sortie de l'encodeur autant de\n",
        "  # fois que l'on souhaite de caractères d'output. C'est un moyen simple de\n",
        "  # conditionner le décodage du résultat sur l'encodage de l'équation\n",
        "  model.add(keras.layers.RepeatVector(2 * n_digits))\n",
        "  # Notez bien l'argument return_sequences=True, sans celui-ci nous ne\n",
        "  # produirions qu'une seule sortie\n",
        "  model.add(keras.layers.GRU(hidden_size, return_sequences=True))\n",
        "\n",
        "  # On applique une couche de sortie dense à chaque timestep\n",
        "  model.add(keras.layers.TimeDistributed(\n",
        "      keras.layers.Dense(len(index_to_char), activation=\"softmax\")))\n",
        "\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "\n",
        "model = rnn_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5CZkw9e6SrC"
      },
      "source": [
        "## Entraînement du modèle\n",
        "\n",
        "On affichera régulièrement des prédictions sur des exemples stables pour voir l'évolution du modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trnzc6lTrZPv"
      },
      "source": [
        "# On utilisera les mêmes exemples à chaque évaluation pour voir le modèle\n",
        "# progresser\n",
        "n_test = 20\n",
        "indexes = numpy.random.choice(X_test.shape[0], replace=False, size=n_test)\n",
        "X_examples, y_examples = X_test[indexes], y_test[indexes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA6VhCgGz9YC"
      },
      "source": [
        "def examples() -> None:\n",
        "  guesses = numpy.argmax(model.predict(X_examples, verbose=0), axis=-1)\n",
        "  for encoded_equation, encoded_result, encoded_guess in zip(\n",
        "      X_examples, y_examples, guesses):\n",
        "    equation = decode(encoded_equation[::-1])\n",
        "    result = decode(encoded_result)\n",
        "    guess = decode(encoded_guess)\n",
        "    print(f\"{equation} = {result} ?= {guess}\")\n",
        "\n",
        "for i in range(10):\n",
        "  model.fit(X_train,\n",
        "            y_train,\n",
        "            batch_size=4096,\n",
        "            epochs=10,\n",
        "            verbose=True,\n",
        "            validation_data=(X_test, y_test))\n",
        "  print()\n",
        "  print(\"─\" * 50)\n",
        "  print(f\"Après {(i + 1) * 10} epochs :\")\n",
        "  examples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eCiLC1Z6an4"
      },
      "source": [
        "## Évaluation du modèle\n",
        "\n",
        "Pour évaluer notre modèle, nous allons calculer 3 éléments sur l'ensemble de test :\n",
        "\n",
        "- les prédictions illégales (quand la sortie du modèle ne peut pas être interprétée comme un flottant)\n",
        "- l'accuracy\n",
        "- l'erreur fractionnelle ($\\frac{y_{pred} - y}{y}$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-5SXuc0ETb"
      },
      "source": [
        "def evaluate() -> None:\n",
        "  # Calcul des prédictions du modèle\n",
        "  predictions = numpy.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "  # Décodage des prédictions du modèle en chaîne de caractères\n",
        "  str_predictions = numpy.apply_along_axis(decode, axis=1, arr=predictions)\n",
        "\n",
        "  # Décodage des prédictions du modèle en flottants\n",
        "  # Parfois la chaîne de caractères émise ne représente pas un flottant valide\n",
        "  # On crée un masque booléen pour pouvoir filtrer ces éléments à posteriori\n",
        "  illegal_predictions_mask = numpy.zeros(X_test.shape[0], numpy.bool)\n",
        "  float_predictions = []\n",
        "  for i, str_prediction in enumerate(str_predictions):\n",
        "    try:\n",
        "      float_prediction = float(str_prediction)\n",
        "      float_predictions.append(float_prediction)\n",
        "    except ValueError:\n",
        "      illegal_predictions_mask[i] = True\n",
        "  illegal_ratio = illegal_predictions_mask.sum() / X_test.shape[0]\n",
        "  print(f\"Pourcentage de prédictions illégales : {illegal_ratio * 100}%\")\n",
        "\n",
        "  y_pred = numpy.array(float_predictions, numpy.float32)\n",
        "  y = numpy.apply_along_axis(decode, 1, y_test).astype(numpy.float32)\n",
        "  y = y[~illegal_predictions_mask]\n",
        "\n",
        "  accuracy = (y == y_pred).sum() / X_test.shape[0]\n",
        "  print(f\"Accuracy : {accuracy:.2f}\")\n",
        "\n",
        "  y_denominator = numpy.copy(y)\n",
        "  y_denominator[y == 0] = 1\n",
        "\n",
        "  fractional_difference = (y_pred - y) / y_denominator\n",
        "\n",
        "  print(f\"Moyenne de l'erreur fractionnelle : {fractional_difference.mean()}\")\n",
        "\n",
        "  plt.hist(fractional_difference, bins=1000)\n",
        "  plt.title(\"Vue globale de la distribution des erreurs fractionnelles\")\n",
        "  plt.xlabel(\"Erreur fractionnelle\")\n",
        "  plt.ylabel(\"Décompte d'exemples\")\n",
        "  plt.xscale(\"symlog\")\n",
        "  plt.yscale(\"log\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.hist(fractional_difference, bins=20, range=(-0.1, 0.1))\n",
        "  plt.title(\"Vue zoomée sur 0 de la distribution des erreurs fractionnelles\")\n",
        "  plt.xlabel(\"Erreur fractionnelle\")\n",
        "  plt.ylabel(\"Décompte d'exemples\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}